<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yoursite.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="涉猎的主要编程语言为 C、Go，分布式存储和对象存储.https:&#x2F;&#x2F;github.com&#x2F;perrynzhou。">
<meta property="og:type" content="website">
<meta property="og:title" content="perrynzhou">
<meta property="og:url" content="http://yoursite.com/page/4/index.html">
<meta property="og:site_name" content="perrynzhou">
<meta property="og:description" content="涉猎的主要编程语言为 C、Go，分布式存储和对象存储.https:&#x2F;&#x2F;github.com&#x2F;perrynzhou。">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="perrynzhou">
<meta property="article:tag" content="C">
<meta property="article:tag" content=" Go">
<meta property="article:tag" content=" 分布式存储">
<meta property="article:tag" content=" 对象存储">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://yoursite.com/page/4/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>perrynzhou</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">perrynzhou</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">一个专注存储技术的疯子,https://github.com/perrynzhou</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/15/glusterfs%E5%B0%8F%E6%96%87%E4%BB%B6%E8%B0%83%E4%BC%98%E6%8C%87%E5%8D%97/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="perrynzhou">
      <meta itemprop="description" content="涉猎的主要编程语言为 C、Go，分布式存储和对象存储.https://github.com/perrynzhou。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="perrynzhou">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/15/glusterfs%E5%B0%8F%E6%96%87%E4%BB%B6%E8%B0%83%E4%BC%98%E6%8C%87%E5%8D%97/" class="post-title-link" itemprop="url">glusterfs小文件调优指南</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-04-15 12:56:18 / Modified: 13:29:24" itemprop="dateCreated datePublished" datetime="2020-04-15T12:56:18+08:00">2020-04-15</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h4 id="glusterfs-小文件调优指南"><a href="#glusterfs-小文件调优指南" class="headerlink" title="glusterfs 小文件调优指南"></a>glusterfs 小文件调优指南</h4><h5 id="获取glusterfs参数说明和默认值"><a href="#获取glusterfs参数说明和默认值" class="headerlink" title="获取glusterfs参数说明和默认值"></a>获取glusterfs参数说明和默认值</h5><ul>
<li><p>glusterfs获取所有可用参数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># gluster volume set help</span><br></pre></td></tr></table></figure></li>
<li><p>获取指定参数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># gluster volume set help|grep &quot;cache-min-file-size&quot; -A7</span><br></pre></td></tr></table></figure>
<h5 id="glusterfs-volume调优参数"><a href="#glusterfs-volume调优参数" class="headerlink" title="glusterfs volume调优参数"></a>glusterfs volume调优参数</h5></li>
<li><p>1.目录操作性能</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">Option: performance.readdir-ahead</span><br><span class="line">Default Value: on</span><br><span class="line">Description: enable&#x2F;disable readdir-ahead translator in the volume.</span><br><span class="line"></span><br><span class="line">Option: performance.rda-cache-limit</span><br><span class="line">Default Value: 10MB</span><br><span class="line">Description: maximum size of cache consumed by readdir-ahead xlator. This value is global and total memory consumption by readdir-ahead is capped by this value, irrespective of the number&#x2F;size of directories cached</span><br><span class="line"></span><br><span class="line">Option: cluster.readdir-optimize</span><br><span class="line">Default Value: off</span><br><span class="line">Description: This option if set to ON enables the optimization that allows DHT to requests non-first subvolumes to filter out directory entries.</span><br><span class="line"></span><br><span class="line">Option: cluster.lookup-unhashed</span><br><span class="line">Default Value: on</span><br><span class="line">Description: This option if set to ON, does a lookup through all the sub-volumes, in case a lookup didn&#39;t return any result from the hash subvolume. If set to OFF, it does not do a lookup on the remaining subvolumes.</span><br><span class="line"></span><br><span class="line">Option: performance.parallel-readdir</span><br><span class="line">Default Value: off</span><br><span class="line">Description: If this option is enabled, the readdir operation is performed in parallel on all the bricks, thus improving the performance of readdir. Note that the performance improvement is higher in large clusters</span><br><span class="line"></span><br><span class="line">gluster volume set dht_vol performance.readdir-ahead on</span><br><span class="line">gluster volume set dht_vol cluster.readdir-optimize on</span><br><span class="line">gluster volume set dht_vol cluster.lookup-unhashed off</span><br><span class="line">gluster volume set dht_vol performance.parallel-readdir on</span><br><span class="line">&#x2F;&#x2F;默认是关闭</span><br><span class="line">gluster volume set dht_vol group metadata-cache</span><br></pre></td></tr></table></figure></li>
<li><p>2.inode缓存大小</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;官方解释</span><br><span class="line">Option: network.inode-lru-limit</span><br><span class="line">Default Value: 16384</span><br><span class="line">Description: Specifies the limit on the number of inodes in the lru list of the inode cache.</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;设置</span><br><span class="line">gluster volume set dht_vol network.inode-lru-limit 100000</span><br></pre></td></tr></table></figure></li>
<li><p>3.实际IO操作线程调整</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;官方解释</span><br><span class="line">Option: performance.io-thread-count</span><br><span class="line">Default Value: 16</span><br><span class="line">Description: Number of threads in IO threads translator which perform concurrent IO operations</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 设置值小于等于可用CPU的合数</span><br><span class="line">gluster volume set dht_vol performance.io-thread-count 32</span><br></pre></td></tr></table></figure></li>
<li><p>4.客户端rpc请求吞吐量设置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Option: server.outstanding-rpc-limit</span><br><span class="line">Default Value: 64</span><br><span class="line">Description: Parameter to throttle the number of incoming RPC requests from a client. 0 means no limit (can potentially run out of memory)</span><br><span class="line"></span><br><span class="line">gluster volume set dht_vol server.outstanding-rpc-limit 512</span><br></pre></td></tr></table></figure>
</li>
<li><p>5.event线程数设置（提高性能,降低响应时间)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;官方解释</span><br><span class="line">Option: client.event-threads</span><br><span class="line">Default Value: 2</span><br><span class="line">Description: Specifies the number of event threads to execute in parallel. Larger values would help process responses faster, depending on available processing power. Range 1-32 threads.</span><br><span class="line"></span><br><span class="line">Option: server.event-threads</span><br><span class="line">Default Value: 2</span><br><span class="line">Description: Specifies the number of event threads to execute in parallel. Larger values would help process responses faster, depending on available processing power.</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;设置超过可用CPU核数会导致context切换严重</span><br><span class="line">gluster volume set dht_vol  client.event-threads  8</span><br><span class="line">gluster volume set dht_vol  server.event-threads  8</span><br></pre></td></tr></table></figure></li>
<li><p>6.io-cache调整</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;官方解释</span><br><span class="line"># gluster volume set help|grep &quot;io-cache&quot; -A7</span><br><span class="line">Option: performance.cache-min-file-size</span><br><span class="line">Default Value: 0</span><br><span class="line">Description: Minimum file size which would be cached by the io-cache translator.</span><br><span class="line"></span><br><span class="line">Option: performance.cache-min-file-size</span><br><span class="line">Default Value: 0</span><br><span class="line">Description: Minimum file size which would be cached by the io-cache translator.</span><br><span class="line"></span><br><span class="line">Option: performance.cache-refresh-timeout</span><br><span class="line">Default Value: 1</span><br><span class="line">Description: The cached data for a file will be retained for &#39;cache-refresh-timeout&#39; seconds, after which data re-validation is performed.</span><br><span class="line"></span><br><span class="line">Option: performance.io-cache-pass-through</span><br><span class="line">Default Value: false</span><br><span class="line">Description: Enable&#x2F;Disable io cache translator</span><br><span class="line"></span><br><span class="line">Option: performance.io-cache</span><br><span class="line">Default Value: on</span><br><span class="line">Description: enable&#x2F;disable io-cache translator in the volume.</span><br><span class="line"></span><br><span class="line">Option: performance.open-behind</span><br><span class="line">Default Value: on</span><br><span class="line">Description: enable&#x2F;disable open-behind translator in the volume.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;当前我们采用opencas作为glusterfsd的后端存储，同时我们业务场景又是存储10亿+的小文件，因此IO-cache开启的意义不大,默认是开启（针对大文件效果好)，需要关闭才可以</span><br><span class="line">gluster volume set dht_vol  performance.io-cache  off</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h5 id="gluster-volume调优样例"><a href="#gluster-volume调优样例" class="headerlink" title="gluster volume调优样例"></a>gluster volume调优样例</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"># gluster volume info warm_vol1 </span><br><span class="line"> </span><br><span class="line">Volume Name: warm_vol1</span><br><span class="line">Type: Distribute</span><br><span class="line">Volume ID: d36874f3-60a0-458a-88b3-7f5ed18c645e</span><br><span class="line">Status: Started</span><br><span class="line">Snapshot Count: 0</span><br><span class="line">Number of Bricks: 2</span><br><span class="line">Transport-type: tcp</span><br><span class="line">Bricks:</span><br><span class="line">Brick1: 172.21.73.96:&#x2F;glusterfs&#x2F;warmvol1&#x2F;data1&#x2F;brick1</span><br><span class="line">Brick2: 172.21.73.96:&#x2F;glusterfs&#x2F;warmvol1&#x2F;data2&#x2F;brick1</span><br><span class="line">Options Reconfigured:</span><br><span class="line">performance.rda-cache-limit: 1024MB</span><br><span class="line">client.event-threads: 8</span><br><span class="line">server.outstanding-rpc-limit: 512</span><br><span class="line">performance.io-thread-count: 32</span><br><span class="line">server.event-threads: 8</span><br><span class="line">network.inode-lru-limit: 500000</span><br><span class="line">performance.read-ahead-page-count: 16</span><br><span class="line">cluster.min-free-inodes: 25%</span><br><span class="line">performance.readdir-ahead: on</span><br><span class="line">cluster.readdir-optimize: on</span><br><span class="line">cluster.lookup-optimize: on</span><br><span class="line">performance.io-cache: off</span><br><span class="line">cluster.lookup-unhashed: off</span><br><span class="line">performance.parallel-readdir: on</span><br><span class="line">storage.fips-mode-rchecksum: on</span><br></pre></td></tr></table></figure>
<h5 id="linux-网络参数调优"><a href="#linux-网络参数调优" class="headerlink" title="linux 网络参数调优"></a>linux 网络参数调优</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;vi &#x2F;etc&#x2F;sysctl.conf 添加如下内容</span><br><span class="line">net.core.rmem_max&#x3D;67108864</span><br><span class="line">net.core.wmem_max&#x3D;67108864</span><br><span class="line">net.ipv4.tcp_wmem&#x3D;33554432</span><br><span class="line">net.ipv4.tcp_rmem&#x3D;33554432</span><br><span class="line">net.core.netdev_max_backlog&#x3D;30000</span><br><span class="line">net.ipv4.tcp_congestion_control&#x3D;htcp</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; sysctl -p 生效</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/14/%E4%BD%BF%E7%94%A8-Intel-Open-Cas%E5%8A%A0%E9%80%9Fglusterfs/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="perrynzhou">
      <meta itemprop="description" content="涉猎的主要编程语言为 C、Go，分布式存储和对象存储.https://github.com/perrynzhou。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="perrynzhou">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/14/%E4%BD%BF%E7%94%A8-Intel-Open-Cas%E5%8A%A0%E9%80%9Fglusterfs/" class="post-title-link" itemprop="url">使用 Intel Open Cas加速glusterfs</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-04-14 18:54:16 / Modified: 18:55:44" itemprop="dateCreated datePublished" datetime="2020-04-14T18:54:16+08:00">2020-04-14</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="Open-Cas-架构概览"><a href="#Open-Cas-架构概览" class="headerlink" title="Open Cas 架构概览"></a>Open Cas 架构概览</h3><ul>
<li><p>数据从HDD盘读取然后拷贝到open cas 的cache中，后续数据读取都是从内存读取，提高读写效率。</p>
</li>
<li><p>在write-through模式，所有的数据都是同步刷新到open cas的ssd和后端hdd硬盘中。</p>
</li>
<li><p>在write-back模式中，所有数据同步写入open cas的ssd中，然后异步刷新到HDD中。</p>
</li>
<li><p>open cas 缓存满后，采用open cas的淘汰算法，用最新写入的数据淘汰以前旧数据，已达到oepn cas始终可以缓存数据。</p>
<p><img src="https://open-cas.github.io/images/guide_figure1.jpg" alt="alt text"> </p>
</li>
</ul>
<h3 id="系统组件以来"><a href="#系统组件以来" class="headerlink" title="系统组件以来"></a>系统组件以来</h3><ul>
<li>sed</li>
<li>make</li>
<li>gcc</li>
<li>kernel-devel</li>
<li>kernel-headers</li>
<li>python3</li>
<li>lsblk</li>
<li>argparse (python module)</li>
</ul>
<h3 id="安装linux-open-cas"><a href="#安装linux-open-cas" class="headerlink" title="安装linux open cas"></a>安装linux open cas</h3><h5 id="1-open-cas-由kernel-modules和cli工具组成"><a href="#1-open-cas-由kernel-modules和cli工具组成" class="headerlink" title="1.open cas 由kernel modules和cli工具组成"></a>1.open cas 由kernel modules和cli工具组成</h5><h5 id="2-为了获取最佳性能，强烈推荐在SSD-device采用noop的IO调度策略"><a href="#2-为了获取最佳性能，强烈推荐在SSD-device采用noop的IO调度策略" class="headerlink" title="2.为了获取最佳性能，强烈推荐在SSD device采用noop的IO调度策略"></a>2.为了获取最佳性能，强烈推荐在SSD device采用noop的IO调度策略</h5><h5 id="3-具体安装步骤"><a href="#3-具体安装步骤" class="headerlink" title="3.具体安装步骤:"></a>3.具体安装步骤:</h5><ul>
<li><p>下载open cas linux source</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https:&#x2F;&#x2F;github.com&#x2F;Open-CAS&#x2F;open-cas-linux</span><br></pre></td></tr></table></figure>



</li>
</ul>
<ul>
<li><p>获取子模块</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd open-cas-linux </span><br><span class="line">git submodule update –init</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置和安装</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">.&#x2F;configure</span><br><span class="line">make</span><br><span class="line">make install</span><br></pre></td></tr></table></figure>
</li>
<li><p>检查和验证</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cas_disk.ko  &#x2F;&#x2F;open cas 磁盘内核模块</span><br><span class="line">cas_cache.ko &#x2F;&#x2F;open cas 缓存内核模块</span><br><span class="line">casadm       &#x2F;&#x2F;open cas 管理员工具</span><br><span class="line">casadm -V    &#x2F;&#x2F;install 检验</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h3 id="open-cas配置"><a href="#open-cas配置" class="headerlink" title="open cas配置"></a>open cas配置</h3><ul>
<li><p>配置文件在utils/opencas.conf中，包括cache的配置和core devices的配置</p>
<ul>
<li><p>caches配置说明</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1.cache id:执行设备的启动实例ID,整形取值范围在1~16384</span><br><span class="line">2.path:指向ssd的磁盘路径</span><br><span class="line">3.desired mode:预期模式，一共有5中模式，分别是write-through&#x2F;write-back&#x2F;write-only&#x2F;pass-through</span><br><span class="line">4.extra fields:用户自定义IO配置</span><br><span class="line">	4.1 ioclass_file：允许用户加载自定义IO策略</span><br><span class="line">   	4.2 cleaning_policy ：允许用户缓存清理的策略，包括了acp&#x2F;alru&#x2F;nop</span><br><span class="line">	4.3 promotion_policy ：允许用户使用缓存的推进策略，包括了always&#x2F;nhit</span><br></pre></td></tr></table></figure>
</li>
<li><p>core devices配置说明</p>
</li>
</ul>
</li>
</ul>
<pre><code>1.cache id:每个core device对应的Cache id，整形，取值范围0~4095
2.core id:每个core device的id
3.path:core device的路径
    //每个cache和core devices必须执行已经存储在hdd和ssd,core device应该引用wwn的标识，cache device必须顺序数据。</code></pre><ul>
<li><p>配置样例</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">## Caches configuration section</span><br><span class="line"></span><br><span class="line">[caches]</span><br><span class="line"></span><br><span class="line">## Cache ID Cache device Cache mode Extra fields (optional)</span><br><span class="line"></span><br><span class="line">1 &#x2F;dev&#x2F;disk&#x2F;by-id&#x2F;nvme-INTEL_SSD WT ioclass_file&#x3D;&#x2F;etc&#x2F;opencas&#x2F;ioclass-config.csv</span><br><span class="line"></span><br><span class="line">## Core devices configuration</span><br><span class="line"></span><br><span class="line">[cores]</span><br><span class="line"></span><br><span class="line">## Cache ID Core ID Core device</span><br><span class="line"></span><br><span class="line">1 1 &#x2F;dev&#x2F;disk&#x2F;by-id&#x2F;wwn-0x50014ee0aed22393</span><br><span class="line"></span><br><span class="line">1 2 &#x2F;dev&#x2F;disk&#x2F;by-id&#x2F;wwn-0x50014ee0042769ef</span><br><span class="line"></span><br><span class="line">1 3 &#x2F;dev&#x2F;disk&#x2F;by-id&#x2F;wwn-0x50014ee00429bf94</span><br><span class="line"></span><br><span class="line">1 4 &#x2F;dev&#x2F;disk&#x2F;by-id&#x2F;wwn-0x50014ee0aed45a6d</span><br><span class="line"></span><br><span class="line">1 5 &#x2F;dev&#x2F;disk&#x2F;by-id&#x2F;wwn-0x50014ee6b11be556</span><br><span class="line"></span><br><span class="line">1 6 &#x2F;dev&#x2F;disk&#x2F;by-id&#x2F;wwn-0x50014ee0aed229a4</span><br><span class="line"></span><br><span class="line">1 7 &#x2F;dev&#x2F;disk&#x2F;by-id&#x2F;wwn-0x50014ee004276c68</span><br></pre></td></tr></table></figure>



</li>
</ul>
<ul>
<li><p>cas管理工具</p>
<ul>
<li><p>手动配置 write-through 模式</p>
<ul>
<li>在该模式下，   caching  software 写入数据到flash device，然后顺序的写到到core device中，这种模式100%保证core device中数据和cache中数据一致，同时可以共享给其他的服务读取，这种类型可以加速读操作</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">casadm -S -i 1 -d &#x2F;dev&#x2F;sdc  &#x2F;&#x2F;创建id&#x3D;1的cache</span><br><span class="line">casadm -A -i 1 -d &#x2F;dev&#x2F;sdb  &#x2F;&#x2F;匹配&#x2F;dev&#x2F;sdb到cache</span><br></pre></td></tr></table></figure>
</li>
<li><p>手动配置write-back模式</p>
<ul>
<li>在该模式下， caching  software首先把数据先写入到cache中，然后通知用户写完毕了，最后周期性的把数据写入到core device中,write-back模式提高了读写性能，但是会有数据丢失的风险  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">casadm -S -i 1 -d &#x2F;dev&#x2F;sdc -c wb</span><br><span class="line">casadm -A -i 1 -d &#x2F;dev&#x2F;sdb  &#x2F;&#x2F;匹配&#x2F;dev&#x2F;sdb到cache</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>手动配置Write-around模式</p>
<ul>
<li><p>在write-around模式下， 只有block数据已经存在于cache中，caching  software把数据才会写入到flash device中，然后顺序写数据到core device.这种模式100%保证core device和cache一致， 写回操作进一步优化了缓存，以避免在写入数据且随后不经常重新读取数据的情况下对缓存的污染 。</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">casadm -S -i 1 -d &#x2F;dev&#x2F;sdc -c wa</span><br></pre></td></tr></table></figure>
</li>
<li><p>手动配置pass-through模式</p>
</li>
<li><p>在该模式下,caching software所有操作都绕开cache.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">casadm -S -i 1 -d &#x2F;dev&#x2F;sdc -c pt</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>手动配置write-only模式</p>
<ul>
<li>在write-only模式下,缓存系统先把数据写入到cache中，然后通知应用端写完成。后续周期性的同步写到core device中,当有新的读请求。只有当之前写入数据在cache device中，读请求会绕开cache software,直接读取caching device的数据。该模式仅仅提高写性能，但是会有数据丢失风险。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">casadm -S -i 1 -d &#x2F;dev&#x2F;sdc -c wo</span><br></pre></td></tr></table></figure>


</li>
</ul>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/14/glusterfs-issue%E5%88%97%E8%A1%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="perrynzhou">
      <meta itemprop="description" content="涉猎的主要编程语言为 C、Go，分布式存储和对象存储.https://github.com/perrynzhou。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="perrynzhou">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/14/glusterfs-issue%E5%88%97%E8%A1%A8/" class="post-title-link" itemprop="url">glusterfs and opencas issue列表</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-04-14 18:42:25" itemprop="dateCreated datePublished" datetime="2020-04-14T18:42:25+08:00">2020-04-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-22 19:55:46" itemprop="dateModified" datetime="2020-04-22T19:55:46+08:00">2020-04-22</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="issue-列表"><a href="#issue-列表" class="headerlink" title="issue 列表"></a>issue 列表</h3><ul>
<li>1.glusterfsd crash due to health-check failed, going down ,system call errorno not return<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https:&#x2F;&#x2F;github.com&#x2F;gluster&#x2F;glusterfs&#x2F;issues&#x2F;1168</span><br></pre></td></tr></table></figure></li>
<li>2.glusterfsd memory leak killed by os #1166<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https:&#x2F;&#x2F;github.com&#x2F;gluster&#x2F;glusterfs&#x2F;issues&#x2F;1166</span><br></pre></td></tr></table></figure></li>
<li>3.Major bug,glusterfsd consume to much cpu resource #1133<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https:&#x2F;&#x2F;github.com&#x2F;gluster&#x2F;glusterfs&#x2F;issues&#x2F;1133</span><br></pre></td></tr></table></figure></li>
<li><ol start="4">
<li>opencase case write page lost</li>
</ol>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https:&#x2F;&#x2F;github.com&#x2F;Open-CAS&#x2F;open-cas-linux&#x2F;issues&#x2F;396</span><br></pre></td></tr></table></figure>

<ul>
<li>5.Fatal Bug:distribute replica 3,one brick of data is different from another replicate one brick #1184</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https:&#x2F;&#x2F;github.com&#x2F;gluster&#x2F;glusterfs&#x2F;issues&#x2F;1184</span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/14/glusterfs-cluster-read-hash-mode%E7%9A%84%E4%BD%9C%E7%94%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="perrynzhou">
      <meta itemprop="description" content="涉猎的主要编程语言为 C、Go，分布式存储和对象存储.https://github.com/perrynzhou。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="perrynzhou">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/14/glusterfs-cluster-read-hash-mode%E7%9A%84%E4%BD%9C%E7%94%A8/" class="post-title-link" itemprop="url">glusterfs cluster.read-hash-mode的作用</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-04-14 18:39:02 / Modified: 18:39:54" itemprop="dateCreated datePublished" datetime="2020-04-14T18:39:02+08:00">2020-04-14</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="1-官方解释"><a href="#1-官方解释" class="headerlink" title="1.官方解释"></a>1.官方解释</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@centos-linux ~]$ gluster volume set help|grep read-hash-mode -A7</span><br><span class="line">Option: cluster.read-hash-mode</span><br><span class="line">Default Value: 1</span><br><span class="line">Description: inode-read fops happen only on one of the bricks in replicate. AFR will prefer the one computed using the method specified using this option.</span><br><span class="line">0 &#x3D; first readable child of AFR, starting from 1st child.</span><br><span class="line">1 &#x3D; hash by GFID of file (all clients use same subvolume).</span><br><span class="line">2 &#x3D; hash by GFID of file and client PID.</span><br><span class="line">3 &#x3D; brick having the least outstanding read requests.</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/14/glusterfs-%E8%B0%83%E8%AF%95%E7%8E%AF%E5%A2%83%E6%9E%84%E5%BB%BA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="perrynzhou">
      <meta itemprop="description" content="涉猎的主要编程语言为 C、Go，分布式存储和对象存储.https://github.com/perrynzhou。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="perrynzhou">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/14/glusterfs-%E8%B0%83%E8%AF%95%E7%8E%AF%E5%A2%83%E6%9E%84%E5%BB%BA/" class="post-title-link" itemprop="url">glusterfs 调试环境构建</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-04-14 18:35:55" itemprop="dateCreated datePublished" datetime="2020-04-14T18:35:55+08:00">2020-04-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-06-01 21:20:39" itemprop="dateModified" datetime="2020-06-01T21:20:39+08:00">2020-06-01</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="Debug-Glusterfs"><a href="#Debug-Glusterfs" class="headerlink" title="Debug Glusterfs"></a>Debug Glusterfs</h3><h4 id="Download-source"><a href="#Download-source" class="headerlink" title="Download source"></a>Download source</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> git <span class="built_in">clone</span> https://github.com/gluster/glusterfs.git</span></span><br></pre></td></tr></table></figure>



<h4 id="Install-Deps"><a href="#Install-Deps" class="headerlink" title="Install Deps"></a>Install Deps</h4><ul>
<li>centos7 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># yum install autoconf automake bison cmockery2-devel dos2unix flex fuse-devel glib2-devel libacl-devel libaio-devel libattr-devel libcurl-devel libibverbs-devel librdmacm-devel libtirpc-devel libtool libxml2-devel lvm2-devel make openssl-devel pkgconfig pyliblzma python-devel python-eventlet python-netifaces python-paste-deploy python-simplejson python-sphinx python-webob pyxattr readline-devel rpm-build sqlite-devel systemtap-sdt-devel tar userspace-rcu-devel -y</span><br></pre></td></tr></table></figure></li>
<li>centos8 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">yum -y install gcc gcc-c++ make expat-devel  autoconf automake libtool flex bison  openssl-devel  libuuid-devel  libacl-devel  libxml2-devel libtirpc-devel  rdma-core-devel readline-devel libaio-devel </span><br><span class="line">yum -y install autoconf automake bison dos2unix flex fuse-devel glib2-devel libacl-devel libaio-devel libattr-devel libcurl-devel libibverbs librdmacm libtirpc-devel libtool libxml2-devel lvm2-libs make openssl-devel pkgconf python36-devel readline-devel rpm-build sqlite-devel systemtap-sdt-devel tar</span><br><span class="line">wget https:&#x2F;&#x2F;github.com&#x2F;urcu&#x2F;userspace-rcu&#x2F;archive&#x2F;v0.7.16.tar.gz -O userspace-rcu-0.7.16.tar.gz</span><br><span class="line">tar -xf userspace-rcu-0.7.16.tar.gz</span><br><span class="line">cd ~&#x2F;userspace-rcu-0.7.16&#x2F;</span><br><span class="line">.&#x2F;bootstrap</span><br><span class="line">make</span><br><span class="line">make install</span><br><span class="line"></span><br><span class="line">find &#x2F;usr&#x2F; -name \*liburcu-bp.so\*</span><br><span class="line">ldconfig -v | grep liburcu-bp.so</span><br><span class="line">echo &#39;&#x2F;usr&#x2F;local&#x2F;lib&#39; &gt; &#x2F;etc&#x2F;ld.so.conf.d&#x2F;userspace-rcu.conf</span><br></pre></td></tr></table></figure></li>
<li>debian</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># sudo apt-get install make automake autoconf libtool flex bison pkg-config libssl-dev libxml2-dev python-dev libaio-dev libibverbs-dev librdmacm-dev libreadline-dev liblvm2-dev libglib2.0-dev liburcu-dev libcmocka-dev libsqlite3-dev libacl1-dev uuid uuid-dev</span><br></pre></td></tr></table></figure>


<h4 id="Build-With-Debug"><a href="#Build-With-Debug" class="headerlink" title="Build With Debug"></a>Build With Debug</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">cd</span> glusterfs-6.5</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> ./autogen.sh</span></span><br><span class="line"><span class="meta">#</span><span class="bash">CFLAGS=<span class="string">"-g3 -gdwarf-2  -O0"</span>  ./configure  --<span class="built_in">enable</span>-debug --<span class="built_in">enable</span>-gnfs  --without-libtirpc </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> make -j4</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> make install</span></span><br></pre></td></tr></table></figure>



<h4 id="Create-Mount-Point"><a href="#Create-Mount-Point" class="headerlink" title="Create Mount Point"></a>Create Mount Point</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> vgcreate --physicalextentsize 128K gfs_test_vg /dev/sdb</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> lvcreate -L 2G --name gfs_test_lv gfs_test_vg</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> lvdisplay</span></span><br><span class="line">  --- Logical volume ---</span><br><span class="line">  LV Path                /dev/gfs_test_vg/gfs_test_lv</span><br><span class="line">  LV Name                gfs_test_lv</span><br><span class="line">  VG Name                gfs_test_vg</span><br><span class="line">  LV UUID                1uw4WG-cdFi-vtHL-vyCZ-qluF-xknL-1Z8mY3</span><br><span class="line">  LV Write Access        read/write</span><br><span class="line">  LV Creation host, time localhost.localdomain, 2019-10-14 16:40:58 +0800</span><br><span class="line">  LV Status              available</span><br><span class="line">  LV Size                2.00 GiB</span><br><span class="line">  Current LE             16384</span><br><span class="line">  Segments               1</span><br><span class="line">  Allocation             inherit</span><br><span class="line">  Read ahead sectors     auto</span><br><span class="line">  - currently set to     8192</span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">echo</span> <span class="string">"/dev/gfs_test_vg/gfs_test_lv   /data/glusterfs/test_vol/brick1   xfs     defaults        0 0"</span> | tee --append /etc/fstab</span></span><br></pre></td></tr></table></figure>



<h4 id="Begin-Gdb"><a href="#Begin-Gdb" class="headerlink" title="Begin Gdb"></a>Begin Gdb</h4><h6 id="Debug-Volume-Info"><a href="#Debug-Volume-Info" class="headerlink" title="Debug Volume Info"></a>Debug Volume Info</h6><ul>
<li>Set BreakPoint<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#gdb gluster </span><br><span class="line">(gdb)set args volume info</span><br><span class="line">(gdb)br main</span><br></pre></td></tr></table></figure></li>
<li>Core Execute Path<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line">main   gluster&#x2F;cli&#x2F;src&#x2F;cli.c:797</span><br><span class="line">	cli_cmds_register gluster&#x2F;cli&#x2F;src&#x2F;cli-cmd.c:208</span><br><span class="line">		cli_cmd_volume_register  gluster&#x2F;cli&#x2F;src&#x2F;cli_cmd_volume_register:3585</span><br><span class="line">			cli_cmd_register  gluster&#x2F;cli&#x2F;src&#x2F;registry.c:356</span><br><span class="line">				cli_cmd_ingest    gluster&#x2F;cli&#x2F;src&#x2F;registry.c:313</span><br><span class="line"></span><br><span class="line">	cli_input_init gluster&#x2F;cli&#x2F;src&#x2F;cli.c:862</span><br><span class="line">		cli_batch    gluster&#x2F;cli&#x2F;input.c:22</span><br><span class="line">			cli_cmd_process gluster&#x2F;cli&#x2F;src&#x2F;cli-cmd.c:87</span><br><span class="line">				cli_cmd_volume_info_cbk(state-&gt;tree.root.cbkfn) gluster&#x2F;cli&#x2F;src&#x2F;cli-cmd-volume.c:3355</span><br><span class="line">					cli_rpc_prog-&gt;proctable[GLUSTER_CLI_GET_VOLUME] &#123;</span><br><span class="line">					    &#x2F;&#x2F;gluster&#x2F;cli&#x2F;src&#x2F;cli-rpc-ops.c:12152</span><br><span class="line">							struct rpc_clnt_procedure gluster_cli_actors[GLUSTER_CLI_MAXVALUE] &#x3D; &#123;</span><br><span class="line">	    					[GLUSTER_CLI_NULL] &#x3D; &#123;&quot;NULL&quot;, NULL&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_PROBE] &#x3D; &#123;&quot;PROBE_QUERY&quot;, gf_cli_probe&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_DEPROBE] &#x3D; &#123;&quot;DEPROBE_QUERY&quot;, gf_cli_deprobe&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_LIST_FRIENDS] &#x3D; &#123;&quot;LIST_FRIENDS&quot;, gf_cli_list_friends&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_UUID_RESET] &#x3D; &#123;&quot;UUID_RESET&quot;, gf_cli3_1_uuid_reset&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_UUID_GET] &#x3D; &#123;&quot;UUID_GET&quot;, gf_cli3_1_uuid_get&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_CREATE_VOLUME] &#x3D; &#123;&quot;CREATE_VOLUME&quot;, gf_cli_create_volume&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_DELETE_VOLUME] &#x3D; &#123;&quot;DELETE_VOLUME&quot;, gf_cli_delete_volume&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_START_VOLUME] &#x3D; &#123;&quot;START_VOLUME&quot;, gf_cli_start_volume&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_STOP_VOLUME] &#x3D; &#123;&quot;STOP_VOLUME&quot;, gf_cli_stop_volume&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_RENAME_VOLUME] &#x3D; &#123;&quot;RENAME_VOLUME&quot;, gf_cli_rename_volume&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_DEFRAG_VOLUME] &#x3D; &#123;&quot;DEFRAG_VOLUME&quot;, gf_cli_defrag_volume&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_GET_VOLUME] &#x3D; &#123;&quot;GET_VOLUME&quot;, gf_cli_get_volume&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_GET_NEXT_VOLUME] &#x3D; &#123;&quot;GET_NEXT_VOLUME&quot;, gf_cli_get_next_volume&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_SET_VOLUME] &#x3D; &#123;&quot;SET_VOLUME&quot;, gf_cli_set_volume&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_ADD_BRICK] &#x3D; &#123;&quot;ADD_BRICK&quot;, gf_cli_add_brick&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_REMOVE_BRICK] &#x3D; &#123;&quot;REMOVE_BRICK&quot;, gf_cli_remove_brick&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_REPLACE_BRICK] &#x3D; &#123;&quot;REPLACE_BRICK&quot;, gf_cli_replace_brick&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_LOG_ROTATE] &#x3D; &#123;&quot;LOG ROTATE&quot;, gf_cli_log_rotate&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_GETSPEC] &#x3D; &#123;&quot;GETSPEC&quot;, gf_cli_getspec&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_PMAP_PORTBYBRICK] &#x3D; &#123;&quot;PMAP PORTBYBRICK&quot;, gf_cli_pmap_b2p&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_SYNC_VOLUME] &#x3D; &#123;&quot;SYNC_VOLUME&quot;, gf_cli_sync_volume&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_RESET_VOLUME] &#x3D; &#123;&quot;RESET_VOLUME&quot;, gf_cli_reset_volume&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_FSM_LOG] &#x3D; &#123;&quot;FSM_LOG&quot;, gf_cli_fsm_log&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_GSYNC_SET] &#x3D; &#123;&quot;GSYNC_SET&quot;, gf_cli_gsync_set&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_PROFILE_VOLUME] &#x3D; &#123;&quot;PROFILE_VOLUME&quot;, gf_cli_profile_volume&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_QUOTA] &#x3D; &#123;&quot;QUOTA&quot;, gf_cli_quota&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_TOP_VOLUME] &#x3D; &#123;&quot;TOP_VOLUME&quot;, gf_cli_top_volume&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_GETWD] &#x3D; &#123;&quot;GETWD&quot;, gf_cli_getwd&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_STATUS_VOLUME] &#x3D; &#123;&quot;STATUS_VOLUME&quot;, gf_cli_status_volume&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_STATUS_ALL] &#x3D; &#123;&quot;STATUS_ALL&quot;, gf_cli_status_volume_all&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_MOUNT] &#x3D; &#123;&quot;MOUNT&quot;, gf_cli_mount&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_UMOUNT] &#x3D; &#123;&quot;UMOUNT&quot;, gf_cli_umount&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_HEAL_VOLUME] &#x3D; &#123;&quot;HEAL_VOLUME&quot;, gf_cli_heal_volume&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_STATEDUMP_VOLUME] &#x3D; &#123;&quot;STATEDUMP_VOLUME&quot;,</span><br><span class="line">	    					                                  gf_cli_statedump_volume&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_LIST_VOLUME] &#x3D; &#123;&quot;LIST_VOLUME&quot;, gf_cli_list_volume&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_CLRLOCKS_VOLUME] &#x3D; &#123;&quot;CLEARLOCKS_VOLUME&quot;,</span><br><span class="line">	    					                                 gf_cli_clearlocks_volume&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_COPY_FILE] &#x3D; &#123;&quot;COPY_FILE&quot;, gf_cli_copy_file&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_SYS_EXEC] &#x3D; &#123;&quot;SYS_EXEC&quot;, gf_cli_sys_exec&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_SNAP] &#x3D; &#123;&quot;SNAP&quot;, gf_cli_snapshot&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_BARRIER_VOLUME] &#x3D; &#123;&quot;BARRIER VOLUME&quot;, gf_cli_barrier_volume&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_GET_VOL_OPT] &#x3D; &#123;&quot;GET_VOL_OPT&quot;, gf_cli_get_vol_opt&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_BITROT] &#x3D; &#123;&quot;BITROT&quot;, gf_cli_bitrot&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_ATTACH_TIER] &#x3D; &#123;&quot;ATTACH_TIER&quot;, gf_cli_attach_tier&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_TIER] &#x3D; &#123;&quot;TIER&quot;, gf_cli_tier&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_GET_STATE] &#x3D; &#123;&quot;GET_STATE&quot;, gf_cli_get_state&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_RESET_BRICK] &#x3D; &#123;&quot;RESET_BRICK&quot;, gf_cli_reset_brick&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_REMOVE_TIER_BRICK] &#x3D; &#123;&quot;DETACH_TIER&quot;, gf_cli_remove_tier_brick&#125;,</span><br><span class="line">	    					[GLUSTER_CLI_ADD_TIER_BRICK] &#x3D; &#123;&quot;ADD_TIER_BRICK&quot;, gf_cli_add_tier_brick&#125;&#125;;</span><br><span class="line">	</span><br><span class="line">						struct rpc_clnt_program cli_prog &#x3D; &#123;</span><br><span class="line">						    .progname &#x3D; &quot;Gluster CLI&quot;,</span><br><span class="line">						    .prognum &#x3D; GLUSTER_CLI_PROGRAM,</span><br><span class="line">						    .progver &#x3D; GLUSTER_CLI_VERSION,</span><br><span class="line">						    .numproc &#x3D; GLUSTER_CLI_MAXVALUE,</span><br><span class="line">						    .proctable &#x3D; gluster_cli_actors,</span><br><span class="line">						&#125;;</span><br><span class="line">					&#125;</span><br><span class="line">						gf_cli_get_volume   gluster&#x2F;cli&#x2F;src&#x2F;cli-rpc-ops.c:4579</span><br><span class="line">							gf_cli_get_volume_cbk  gluster&#x2F;cli&#x2F;src&#x2F;cli-rpc-ops.c:819</span><br></pre></td></tr></table></figure>


</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/14/glusterfs-%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="perrynzhou">
      <meta itemprop="description" content="涉猎的主要编程语言为 C、Go，分布式存储和对象存储.https://github.com/perrynzhou。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="perrynzhou">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/14/glusterfs-%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E/" class="post-title-link" itemprop="url">glusterfs 参数说明</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-04-14 18:33:31 / Modified: 18:46:26" itemprop="dateCreated datePublished" datetime="2020-04-14T18:33:31+08:00">2020-04-14</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="选项说明"><a href="#选项说明" class="headerlink" title="选项说明"></a>选项说明</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ gluster volume set help</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th align="left">选项</th>
<th align="center">默认值</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left">changelog.changelog-barrier-timeout</td>
<td align="center">120</td>
<td align="left">After ‘timeout’ seconds since the time ‘barrier’ option was set to “on”, unlink/rmdir/rename operations are no longer blocked and previously blocked fops are allowed to go through</td>
</tr>
<tr>
<td align="left">cluster.enable-shared-storage</td>
<td align="center">disable</td>
<td align="left">Create and mount the shared storage volume(gluster_shared_storage) at /var/run/gluster/shared_storage on enabling this option. Unmount and delete the shared storage volume on disabling this option.</td>
</tr>
<tr>
<td align="left">cluster.write-freq-threshold</td>
<td align="center">0</td>
<td align="left">Defines the number of writes, in a promotion/demotion cycle, that would mark a file HOT for promotion. Any file that has write hits less than this value will be considered as COLD and will be demoted.</td>
</tr>
<tr>
<td align="left">cluster.read-freq-threshold</td>
<td align="center">0</td>
<td align="left">Defines the number of reads, in a promotion/demotion cycle, that would mark a file HOT for promotion. Any file that has read hits less than this value will be considered as COLD and will be demoted.</td>
</tr>
<tr>
<td align="left">cluster.tier-pause</td>
<td align="center">off</td>
<td align="left">(null)</td>
</tr>
<tr>
<td align="left">cluster.tier-promote-frequency</td>
<td align="center">120</td>
<td align="left">Frequency to promote files to fast tier</td>
</tr>
<tr>
<td align="left">cluster.tier-demote-frequency</td>
<td align="center">120</td>
<td align="left">Frequency to demote files to slow tier</td>
</tr>
<tr>
<td align="left">cluster.watermark-hi</td>
<td align="center">90</td>
<td align="left">Upper % watermark for promotion. If hot tier fills above this percentage, no promotion will happen and demotion will happen with high probability.</td>
</tr>
<tr>
<td align="left">cluster.watermark-low</td>
<td align="center">75</td>
<td align="left">Lower % watermark. If hot tier is less full than this, promotion will happen and demotion will not happen. If greater than this, promotion/demotion will happen at a probability relative to how full the hot tier is.</td>
</tr>
<tr>
<td align="left">cluster.tier-mode</td>
<td align="center">cache</td>
<td align="left">Either ‘test’ or ‘cache’. Test mode periodically demotes or promotes files automatically based on access. Cache mode does so based on whether the cache is full or not, as specified with watermarks.</td>
</tr>
<tr>
<td align="left">cluster.tier-max-mb</td>
<td align="center">10000</td>
<td align="left">The maximum number of MB that may be migrated in any direction in a given cycle by a single node.</td>
</tr>
<tr>
<td align="left">cluster.tier-max-files</td>
<td align="center">50000</td>
<td align="left">The maximum number of files that may be migrated in any direction in a given cycle by a single node.</td>
</tr>
<tr>
<td align="left">cluster.lookup-unhashed</td>
<td align="center">on</td>
<td align="left">This option if set to ON, does a lookup through all the sub-volumes, in case a lookup didn’t return any result from the hash subvolume. If set to OFF, it does not do a lookup on the remaining subvolumes.</td>
</tr>
<tr>
<td align="left">cluster.lookup-optimize</td>
<td align="center">off</td>
<td align="left">This option if set to ON enables the optimization of -ve lookups, by not doing a lookup on non-hashed subvolumes for files, in case the hashed subvolume does not return any result. This option disregards the lookup-unhashed setting, when enabled.</td>
</tr>
<tr>
<td align="left">cluster.min-free-disk</td>
<td align="center">10%</td>
<td align="left">Percentage/Size of disk space, after which the process starts balancing out the cluster, and logs will appear in log files</td>
</tr>
<tr>
<td align="left">cluster.min-free-inodes</td>
<td align="center">5%</td>
<td align="left">after system has only N% of inodes, warnings starts to appear in log files</td>
</tr>
<tr>
<td align="left">cluster.rebalance-stats</td>
<td align="center">off</td>
<td align="left">This option if set to ON displays and logs the time taken for migration of each file, during the rebalance process. If set to OFF, the rebalance logs will only display the time spent in each directory.</td>
</tr>
<tr>
<td align="left">cluster.subvols-per-directory</td>
<td align="center">null</td>
<td align="left">Specifies the directory layout spread. Takes number of subvolumes as default value.</td>
</tr>
<tr>
<td align="left">cluster.readdir-optimize</td>
<td align="center">off</td>
<td align="left">This option if set to ON enables the optimization that allows DHT to requests non-first subvolumes to filter out directory entries.</td>
</tr>
<tr>
<td align="left">cluster.rebal-throttle</td>
<td align="center">normal</td>
<td align="left">Sets the maximum number of parallel file migrations allowed on a node during the rebalance operation. The default value is normal and allows a max of [($(processing units) - 4) / 2), 2] files to be migrated at a time. Lazy will allow only one file to be migrated at a time and aggressive will allow max of [($(processing units) - 4) / 2), 4]</td>
</tr>
<tr>
<td align="left">cluster.weighted-rebalance</td>
<td align="center">on</td>
<td align="left">When enabled, files will be allocated to bricks with a probability proportional to their size. Otherwise, all bricks will have the same probability (legacy behavior).</td>
</tr>
<tr>
<td align="left">cluster.entry-change-log</td>
<td align="center">on</td>
<td align="left">Entry fops like create/unlink will not perform pre/post fop changelog operations in afr transaction if this option is disabled</td>
</tr>
<tr>
<td align="left">cluster.read-subvolume</td>
<td align="center">null</td>
<td align="left">inode-read fops happen only on one of the bricks in replicate. Afr will prefer the one specified using this option if it is not stale. Option value must be one of the xlator names of the children. Ex: -client-0 till -client-&lt;number-of-bricks - 1&gt;</td>
</tr>
<tr>
<td align="left">cluster.read-subvolume-index</td>
<td align="center">-1</td>
<td align="left">inode-read fops happen only on one of the bricks in replicate. AFR will prefer the one specified using this option if it is not stale. allowed options include -1 till replica-count - 1</td>
</tr>
<tr>
<td align="left">cluster.read-hash-mode</td>
<td align="center">1</td>
<td align="left">inode-read fops happen only on one of the bricks in replicate. AFR will prefer the one computed using the method specified using this option0 = first up server, 1 = hash by GFID of file (all clients use same subvolume), 2 = hash by GFID of file and client PID</td>
</tr>
<tr>
<td align="left">cluster.background-self-heal-count</td>
<td align="center">16</td>
<td align="left">This specifies the number of self-heals that can be performed in background without blocking the fop</td>
</tr>
<tr>
<td align="left">cluster.metadata-self-heal</td>
<td align="center">on</td>
<td align="left">Using this option we can enable/disable metadata i.e. Permissions, ownerships, xattrs self-heal on the file/directory.</td>
</tr>
<tr>
<td align="left">cluster.data-self-heal</td>
<td align="center">on</td>
<td align="left">Using this option we can enable/disable data self-heal on the file. “open” means data self-heal action will only be triggered by file open operations.</td>
</tr>
<tr>
<td align="left">cluster.entry-self-heal</td>
<td align="center">on</td>
<td align="left">Using this option we can enable/disable entry self-heal on the directory.</td>
</tr>
<tr>
<td align="left">cluster.self-heal-daemon</td>
<td align="center">on</td>
<td align="left">This option applies to only self-heal-daemon. Index directory crawl and automatic healing of files will not be performed if this option is turned off.</td>
</tr>
<tr>
<td align="left">cluster.heal-timeout</td>
<td align="center">600</td>
<td align="left">time interval for checking the need to self-heal in self-heal-daemon</td>
</tr>
<tr>
<td align="left">cluster.self-heal-window-size</td>
<td align="center">1</td>
<td align="left">Maximum number blocks per file for which self-heal process would be applied simultaneously.</td>
</tr>
<tr>
<td align="left">cluster.data-change-log</td>
<td align="center">on</td>
<td align="left">Data fops like write/truncate will not perform pre/post fop changelog operations in afr transaction if this option is disabled</td>
</tr>
<tr>
<td align="left">cluster.metadata-change-log</td>
<td align="center">on</td>
<td align="left">Metadata fops like setattr/setxattr will not perform pre/post fop changelog operations in afr transaction if this option is disabled</td>
</tr>
<tr>
<td align="left">cluster.data-self-heal-algorithm</td>
<td align="center">null</td>
<td align="left">Select between “full”, “diff”. The “full” algorithm copies the entire file from source to sink. The “diff” algorithm copies to sink only those blocks whose checksums don’t match with those of source. If no option is configured the option is chosen dynamically as follows: If the file does not exist on one of the sinks or empty file exists or if the source file size is about the same as page size the entire file will be read and written i.e “full” algo, otherwise “diff” algo is chosen.</td>
</tr>
<tr>
<td align="left">cluster.eager-lock</td>
<td align="center">on</td>
<td align="left">Lock phase of a transaction has two sub-phases. First is an attempt to acquire locks in parallel by broadcasting non-blocking lock requests. If lock acquisition fails on any server, then the held locks are unlocked and revert to a blocking locked mode sequentially on one server after another. If this option is enabled the initial broadcasting lock request attempt to acquire lock on the entire file. If this fails, we revert back to the sequential “regional” blocking lock as before. In the case where such an “eager” lock is granted in the non-blocking phase, it gives rise to an opportunity for optimization. i.e, if the next write transaction on the same FD arrives before the unlock phase of the first transaction, it “takes over” the full file lock. Similarly if yet another data transaction arrives before the unlock phase of the “optimized” transaction, that in turn “takes over” the lock as well. The actual unlock now happens at the end of the last “optimized” transaction.</td>
</tr>
<tr>
<td align="left">cluster.quorum-type</td>
<td align="center">none</td>
<td align="left">If value is “fixed” only allow writes if quorum-count bricks are present. If value is “auto” only allow writes if more than half of bricks, or exactly half including the first, are present.</td>
</tr>
<tr>
<td align="left">cluster.quorum-count</td>
<td align="center">null</td>
<td align="left">If quorum-type is “fixed” only allow writes if this many bricks or present. Other quorum types will OVERWRITE this value.</td>
</tr>
<tr>
<td align="left">cluster.choose-local</td>
<td align="center">true</td>
<td align="left">Choose a local subvolume (i.e. Brick) to read from if read-subvolume is not explicitly set.</td>
</tr>
<tr>
<td align="left">cluster.self-heal-readdir-size</td>
<td align="center">1KB</td>
<td align="left">readdirp size for performing entry self-heal</td>
</tr>
<tr>
<td align="left">cluster.ensure-durability</td>
<td align="center">on</td>
<td align="left">Afr performs fsyncs for transactions if this option is on to make sure the changelogs/data is written to the disk</td>
</tr>
<tr>
<td align="left">cluster.consistent-metadata</td>
<td align="center">no</td>
<td align="left">If this option is enabled, readdirp will force lookups on those entries read whose read child is not the same as that of the parent. This will guarantee that all read operations on a file serve attributes from the same subvol as long as it holds a good copy of the file/dir.</td>
</tr>
<tr>
<td align="left">cluster.stripe-block-size</td>
<td align="center">128KB</td>
<td align="left">Size of the stripe unit that would be read from or written to the striped servers.</td>
</tr>
<tr>
<td align="left">cluster.stripe-coalesce</td>
<td align="center">true</td>
<td align="left">Enable/Disable coalesce mode to flatten striped files as stored on the server (i.e., eliminate holes caused by the traditional format).</td>
</tr>
<tr>
<td align="left">cluster.server-quorum-type</td>
<td align="center">(null)</td>
<td align="left">This feature is on the server-side i.e. in glusterd. Whenever the glusterd on a machine observes that the quorum is not met, it brings down the bricks to prevent data split-brains. When the network connections are brought back up and the quorum is restored the bricks in the volume are brought back up.</td>
</tr>
<tr>
<td align="left">cluster.server-quorum-ratio</td>
<td align="center">(null)</td>
<td align="left">Sets the quorum percentage for the trusted storage pool.</td>
</tr>
<tr>
<td align="left">cluster.quorum-reads</td>
<td align="center">no</td>
<td align="left">If quorum-reads is “true” only allow reads if quorum is met when quorum is enabled.</td>
</tr>
<tr>
<td align="left">diagnostics.latency-measurement</td>
<td align="center">off</td>
<td align="left">If on stats related to the latency of each operation would be tracked inside GlusterFS data-structures.</td>
</tr>
<tr>
<td align="left">diagnostics.dump-fd-stats</td>
<td align="center">off</td>
<td align="left">If on stats related to file-operations would be tracked inside GlusterFS data-structures.</td>
</tr>
<tr>
<td align="left">diagnostics.brick-log-level</td>
<td align="center">INFO</td>
<td align="left">Changes the log-level of the bricks</td>
</tr>
<tr>
<td align="left">diagnostics.client-log-level</td>
<td align="center">INFO</td>
<td align="left">Changes the log-level of the clients</td>
</tr>
<tr>
<td align="left">diagnostics.brick-sys-log-level</td>
<td align="center">CRITICAL</td>
<td align="left">Gluster’s syslog log-level</td>
</tr>
<tr>
<td align="left">diagnostics.client-sys-log-level</td>
<td align="center">CRITICAL</td>
<td align="left">Gluster’s syslog log-level</td>
</tr>
<tr>
<td align="left">diagnostics.brick-logger</td>
<td align="center">null</td>
<td align="left">null</td>
</tr>
<tr>
<td align="left">diagnostics.client-logger</td>
<td align="center">null</td>
<td align="left">null</td>
</tr>
<tr>
<td align="left">diagnostics.brick-log-format</td>
<td align="center">null</td>
<td align="left">null</td>
</tr>
<tr>
<td align="left">diagnostics.client-log-format</td>
<td align="center">null</td>
<td align="left">null</td>
</tr>
<tr>
<td align="left">diagnostics.brick-log-buf-size</td>
<td align="center">5</td>
<td align="left">null</td>
</tr>
<tr>
<td align="left">diagnostics.client-log-buf-size</td>
<td align="center">5</td>
<td align="left">null</td>
</tr>
<tr>
<td align="left">diagnostics.brick-log-flush-timeout</td>
<td align="center">20</td>
<td align="left">null</td>
</tr>
<tr>
<td align="left">diagnostics.client-log-flush-timeout</td>
<td align="center">20</td>
<td align="left">null</td>
</tr>
<tr>
<td align="left">disperse.background-heals</td>
<td align="center">8</td>
<td align="left">This option can be used to control number of parallel heals</td>
</tr>
<tr>
<td align="left">disperse.heal-wait-qlength</td>
<td align="center">128</td>
<td align="left">This option can be used to control number of heals that can wait</td>
</tr>
<tr>
<td align="left">disperse.read-policy</td>
<td align="center">round-robin</td>
<td align="left">inode-read fops happen only on ‘k’ number of bricks in n=k+m disperse subvolume. ‘round-robin’ selects the read subvolume using round-robin algo. ‘gfid-hash’ selects read subvolume based on hash of the gfid of that file/directory.</td>
</tr>
<tr>
<td align="left">dht.force-readdirp</td>
<td align="center">on</td>
<td align="left">This option if set to ON, forces the use of readdirp, and hence also displays the stats of the files.</td>
</tr>
<tr>
<td align="left">performance.cache-max-file-size</td>
<td align="center">0</td>
<td align="left">Maximum file size which would be cached by the io-cache translator.</td>
</tr>
<tr>
<td align="left">performance.cache-min-file-size</td>
<td align="center">0</td>
<td align="left">Minimum file size which would be cached by the io-cache translator.</td>
</tr>
<tr>
<td align="left">performance.cache-refresh-timeout</td>
<td align="center">1</td>
<td align="left">The cached data for a file will be retained till ‘cache-refresh-timeout’ seconds, after which data re-validation is performed.</td>
</tr>
<tr>
<td align="left">performance.cache-priority</td>
<td align="center"></td>
<td align="left">Assigns priority to filenames with specific patterns so that when a page needs to be ejected out of the cache, the page of a file whose priority is the lowest will be ejected earlier</td>
</tr>
<tr>
<td align="left">performance.cache-size</td>
<td align="center">32MB</td>
<td align="left">Size of the read cache.</td>
</tr>
<tr>
<td align="left">performance.io-thread-count</td>
<td align="center">16</td>
<td align="left">Number of threads in IO threads translator which perform concurrent IO operations</td>
</tr>
<tr>
<td align="left">performance.high-prio-threads</td>
<td align="center">16</td>
<td align="left">Max number of threads in IO threads translator which perform high priority IO operations at a given time</td>
</tr>
<tr>
<td align="left">performance.normal-prio-threads</td>
<td align="center">16</td>
<td align="left">Max number of threads in IO threads translator which perform normal priority IO operations at a given time</td>
</tr>
<tr>
<td align="left">performance.low-prio-threads</td>
<td align="center">16</td>
<td align="left">Max number of threads in IO threads translator which perform low priority IO operations at a given time</td>
</tr>
<tr>
<td align="left">performance.least-prio-threads</td>
<td align="center">1</td>
<td align="left">Max number of threads in IO threads translator which perform least priority IO operations at a given time</td>
</tr>
<tr>
<td align="left">performance.enable-least-priority</td>
<td align="center">on</td>
<td align="left">Enable/Disable least priority</td>
</tr>
<tr>
<td align="left">performance.least-rate-limit</td>
<td align="center">0</td>
<td align="left">Max number of least priority operations to handle per-second</td>
</tr>
<tr>
<td align="left">performance.flush-behind</td>
<td align="center">on</td>
<td align="left">If this option is set ON, instructs write-behind translator to perform flush in background, by returning success (or any errors, if any of previous writes were failed) to application even before flush FOP is sent to backend filesystem.</td>
</tr>
<tr>
<td align="left">performance.nfs.flush-behind</td>
<td align="center">on</td>
<td align="left">If this option is set ON, instructs write-behind translator to perform flush in background, by returning success (or any errors, if any of previous writes were failed) to application even before flush FOP is sent to backend filesystem.</td>
</tr>
<tr>
<td align="left">performance.write-behind-window-size</td>
<td align="center">1MB</td>
<td align="left">Size of the write-behind buffer for a single file (inode).</td>
</tr>
<tr>
<td align="left">performance.nfs.write-behind-window-size</td>
<td align="center">1MB</td>
<td align="left">Size of the write-behind buffer for a single file (inode).</td>
</tr>
<tr>
<td align="left">performance.strict-o-direct</td>
<td align="center">off</td>
<td align="left">This option when set to off, ignores the O_DIRECT flag.</td>
</tr>
<tr>
<td align="left">performance.nfs.strict-o-direct</td>
<td align="center">off</td>
<td align="left">This option when set to off, ignores the O_DIRECT flag.</td>
</tr>
<tr>
<td align="left">performance.strict-write-ordering</td>
<td align="center">off</td>
<td align="left">Do not let later writes overtake earlier writes even if they do not overlap</td>
</tr>
<tr>
<td align="left">performance.nfs.strict-write-ordering</td>
<td align="center">off</td>
<td align="left">Do not let later writes overtake earlier writes even if they do not overlap</td>
</tr>
<tr>
<td align="left">performance.lazy-open</td>
<td align="center">yes</td>
<td align="left">Perform open in the backend only when a necessary FOP arrives (e.g writev on the FD, unlink of the file). When option is disabled, perform backend open right after unwinding open().</td>
</tr>
<tr>
<td align="left">performance.read-after-open</td>
<td align="center">no</td>
<td align="left">read is sent only after actual open happens and real fd is obtained, instead of doing on anonymous fd (similar to write)</td>
</tr>
<tr>
<td align="left">performance.read-ahead-page-count</td>
<td align="center">4</td>
<td align="left">Number of pages that will be pre-fetched</td>
</tr>
<tr>
<td align="left">performance.md-cache-timeout</td>
<td align="center">1</td>
<td align="left">Time period after which cache has to be refreshed</td>
</tr>
<tr>
<td align="left">performance.write-behind</td>
<td align="center">on</td>
<td align="left">enable/disable write-behind translator in the volume.</td>
</tr>
<tr>
<td align="left">performance.read-ahead</td>
<td align="center">on</td>
<td align="left">enable/disable read-ahead translator in the volume.</td>
</tr>
<tr>
<td align="left">performance.readdir-ahead</td>
<td align="center">off</td>
<td align="left">enable/disable readdir-ahead translator in the volume.</td>
</tr>
<tr>
<td align="left">performance.io-cache</td>
<td align="center">on</td>
<td align="left">enable/disable io-cache translator in the volume.</td>
</tr>
<tr>
<td align="left">performance.quick-read</td>
<td align="center">on</td>
<td align="left">enable/disable quick-read translator in the volume.</td>
</tr>
<tr>
<td align="left">performance.open-behind</td>
<td align="center">on</td>
<td align="left">enable/disable open-behind translator in the volume.</td>
</tr>
<tr>
<td align="left">performance.stat-prefetch</td>
<td align="center">on</td>
<td align="left">enable/disable meta-data caching translator in the volume.</td>
</tr>
<tr>
<td align="left">performance.client-io-threads</td>
<td align="center">off</td>
<td align="left">enable/disable io-threads translator in the client graph of volume.</td>
</tr>
<tr>
<td align="left">performance.nfs.write-behind</td>
<td align="center">on</td>
<td align="left">enable/disable write-behind translator in the volume</td>
</tr>
<tr>
<td align="left">performance.force-readdirp</td>
<td align="center">true</td>
<td align="left">Convert all readdir requests to readdirplus to collect stat info on each entry.</td>
</tr>
<tr>
<td align="left">features.encryption</td>
<td align="center">off</td>
<td align="left">enable/disable client-side encryption for the volume.</td>
</tr>
<tr>
<td align="left">encryption.master-key</td>
<td align="center">null</td>
<td align="left">Pathname of regular file which contains master volume key</td>
</tr>
<tr>
<td align="left">encryption.data-key-size</td>
<td align="center">256</td>
<td align="left">Data key size (bits)</td>
</tr>
<tr>
<td align="left">encryption.block-size</td>
<td align="center">4096</td>
<td align="left">Atom size (bits)</td>
</tr>
<tr>
<td align="left">nfs.enable-ino32</td>
<td align="center">no</td>
<td align="left">For nfs clients or apps that do not support 64-bit inode numbers, use this option to make NFS return 32-bit inode numbers instead. Disabled by default, so NFS returns 64-bit inode numbers.</td>
</tr>
<tr>
<td align="left">nfs.mem-factor</td>
<td align="center">15</td>
<td align="left">Use this option to make NFS be faster on systems by using more memory. This option specifies a multiple that determines the total amount of memory used. Default value is 15. Increase to use more memory in order to improve performance for certain use cases.Please consult gluster-users list before using this option.</td>
</tr>
<tr>
<td align="left">nfs.export-dirs</td>
<td align="center">on</td>
<td align="left">By default, all subvolumes of nfs are exported as individual exports. There are cases where a subdirectory or subdirectories in the volume need to be exported separately. Enabling this option allows any directory on a volumes to be exported separately.Directory exports are enabled by default.</td>
</tr>
<tr>
<td align="left">nfs.export-volumes</td>
<td align="center">on</td>
<td align="left">Enable or disable exporting whole volumes, instead if used in conjunction with nfs3.export-dir, can allow setting up only subdirectories as exports. On by default.</td>
</tr>
<tr>
<td align="left">nfs.addr-namelookup</td>
<td align="center">off</td>
<td align="left">Users have the option of turning on name lookup for incoming client connections using this option. Use this option to turn on name lookups during address-based authentication. Turning this on will enable you to use hostnames in nfs.rpc-auth-* filters. In some setups, the name server can take too long to reply to DNS queries resulting in timeouts of mount requests. By default, name lookup is off</td>
</tr>
<tr>
<td align="left">nfs.dynamic-volumes</td>
<td align="center">off</td>
<td align="left">Internal option set to tell gnfs to use a different scheme for encoding file handles when DVM is being used.</td>
</tr>
<tr>
<td align="left">nfs.register-with-portmap</td>
<td align="center">on</td>
<td align="left">For systems that need to run multiple nfs servers, only one registration is possible with portmap service. Use this option to turn off portmap registration for Gluster NFS. On by default</td>
</tr>
<tr>
<td align="left">nfs.outstanding-rpc-limit</td>
<td align="center">16</td>
<td align="left">Parameter to throttle the number of incoming RPC requests from a client. 0 means no limit (can potentially run out of memory)</td>
</tr>
<tr>
<td align="left">nfs.port</td>
<td align="center">2049</td>
<td align="left">Use this option on systems that need Gluster NFS to be associated with a non-default port number.</td>
</tr>
<tr>
<td align="left">nfs.rpc-auth-unix</td>
<td align="center">on</td>
<td align="left">Disable or enable the AUTH_UNIX authentication type for a particular exported volume overriding defaults and general setting for AUTH_UNIX scheme. Must always be enabled for better interoperability. However, can be disabled if needed. Enabled by default.</td>
</tr>
<tr>
<td align="left">nfs.rpc-auth-null</td>
<td align="center">on</td>
<td align="left">Disable or enable the AUTH_NULL authentication type for a particular exported volume overriding defaults and general setting for AUTH_NULL. Must always be enabled. This option is here only to avoid unrecognized option warnings.</td>
</tr>
<tr>
<td align="left">nfs.rpc-auth-allow</td>
<td align="center">all</td>
<td align="left">Allow a comma separated list of addresses and/or hostnames to connect to the server. By default, all connections are allowed. This allows users to define a rule for a specific exported volume.</td>
</tr>
<tr>
<td align="left">nfs.rpc-auth-reject</td>
<td align="center">none</td>
<td align="left">Reject a comma separated list of addresses and/or hostnames from connecting to the server. By default, all connections are allowed. This allows users to define a rule for a specific exported volume.</td>
</tr>
<tr>
<td align="left">nfs.ports-insecure</td>
<td align="center">off</td>
<td align="left">Allow client connections from unprivileged ports. By default only privileged ports are allowed. Use this option to enable or disable insecure ports for a specific subvolume and to override the global setting set by the previous option.</td>
</tr>
<tr>
<td align="left">nfs.transport-type</td>
<td align="center">(null)</td>
<td align="left">Specifies the nfs transport type. Valid transport types are ‘tcp’ and ‘rdma’.</td>
</tr>
<tr>
<td align="left">nfs.trusted-sync</td>
<td align="center">off</td>
<td align="left">All writes and COMMIT requests are treated as async. This implies that no write requests are guaranteed to be on server disks when the write reply is received at the NFS client. Trusted sync includes trusted-write behaviour. Off by default.</td>
</tr>
<tr>
<td align="left">nfs.trusted-write</td>
<td align="center">off</td>
<td align="left">On an UNSTABLE write from client, return STABLE flag to force client to not send a COMMIT request. In some environments, combined with a replicated GlusterFS setup, this option can improve write performance. This flag allows user to trust Gluster replication logic to sync data to the disks and recover when required. COMMIT requests if received will be handled in a default manner by fsyncing. STABLE writes are still handled in a sync manner. Off by default.</td>
</tr>
<tr>
<td align="left">nfs.volume-access</td>
<td align="center">read-write</td>
<td align="left">Type of access desired for this subvolume: read-only, read-write(default)</td>
</tr>
<tr>
<td align="left">nfs.export-dir</td>
<td align="center"></td>
<td align="left">By default, all subvolumes of nfs are exported as individual exports. There are cases where a subdirectory or subdirectories in the volume need to be exported separately. This option can also be used in conjunction with nfs3.export-volumes option to restrict exports only to the subdirectories specified through this option. Must be an absolute path. Along with path allowed list of IPs/hostname can be associated with each subdirectory. If provided connection will allowed only from these IPs. By default connections from all IPs are allowed. Format:[(hostspec[|hostspec|…])][,…]. Where hostspec can be an IP address, hostname or an IP range in CIDR notation. e.g. /foo(192.168.1.0/24|host1|10.1.1.8),/host2. NOTE: Care must be taken while configuring this option as invalid entries and/or unreachable DNS servers can introduce unwanted delay in all the mount calls.</td>
</tr>
<tr>
<td align="left">nfs.disable</td>
<td align="center">false</td>
<td align="left">This option is used to start or stop the NFS server for individual volumes.</td>
</tr>
<tr>
<td align="left">nfs.nlm</td>
<td align="center">on</td>
<td align="left">This option, if set to ‘off’, disables NLM server by not registering the service with the portmapper. Set it to ‘on’ to re-enable it. Default value: ‘on’</td>
</tr>
<tr>
<td align="left">nfs.acl</td>
<td align="center">on</td>
<td align="left">This option is used to control ACL support for NFS.</td>
</tr>
<tr>
<td align="left">nfs.mount-udp</td>
<td align="center">off</td>
<td align="left">set the option to ‘on’ to enable mountd on UDP. Required for some Solaris and AIX NFS clients. The need for enabling this option often depends on the usage of NLM.</td>
</tr>
<tr>
<td align="left">nfs.mount-rmtab</td>
<td align="center">/var/lib/glusterd/nfs/rmtab</td>
<td align="left">Set the location of the cache file that is used to list all the NFS-clients that have connected through the MOUNT protocol. If this is on shared storage, all GlusterFS servers will update and output (with ‘showmount’) the same list. Set to “/-“ to disable.</td>
</tr>
<tr>
<td align="left">nfs.drc</td>
<td align="center">off</td>
<td align="left">Enable Duplicate Request Cache in gNFS server to improve correctness of non-idempotent operations like write, delete, link, et al</td>
</tr>
<tr>
<td align="left">nfs.drc-size</td>
<td align="center">0x20000</td>
<td align="left">Sets the number of non-idempotent requests to cache in drc</td>
</tr>
<tr>
<td align="left">nfs.read-size</td>
<td align="center">(1 * 1048576ULL)</td>
<td align="left">Size in which the client should issue read requests to the Gluster NFSv3 server. Must be a multiple of 4KB (4096). Min and Max supported values are 4KB (4096) and 1MB (1048576) respectively. If the specified value is within the supported range but not a multiple of 4096, it is rounded up to the nearest multiple of 4096.</td>
</tr>
<tr>
<td align="left">nfs.write-size</td>
<td align="center">(1 * 1048576ULL)</td>
<td align="left">Size in which the client should issue write requests to the Gluster NFSv3 server. Must be a multiple of 1KB (1024). Min and Max supported values are 4KB (4096) and 1MB(1048576) respectively. If the specified value is within the supported range but not a multiple of 4096, it is rounded up to the nearest multiple of 4096.</td>
</tr>
<tr>
<td align="left">nfs.readdir-size</td>
<td align="center">(1 * 1048576ULL)</td>
<td align="left">Size in which the client should issue directory reading requests to the Gluster NFSv3 server. Must be a multiple of 1KB (1024). Min and Max supported values are 4KB (4096) and 1MB (1048576) respectively.If the specified value is within the supported range but not a multiple of 4096, it is rounded up to the nearest multiple of 4096.</td>
</tr>
<tr>
<td align="left">nfs.exports-auth-enable</td>
<td align="center">(null)</td>
<td align="left">Set the option to ‘on’ to enable exports/netgroup authentication in the NFS server and mount daemon.</td>
</tr>
<tr>
<td align="left">nfs.auth-refresh-interval-sec</td>
<td align="center">(null)</td>
<td align="left">Frequency in seconds that the daemon should check for changes in the exports/netgroups file.</td>
</tr>
<tr>
<td align="left">nfs.auth-cache-ttl-sec</td>
<td align="center">(null)</td>
<td align="left">Sets the TTL of an entry in the auth cache. Value is in seconds.</td>
</tr>
<tr>
<td align="left">ganesha.enable</td>
<td align="center">off</td>
<td align="left">export volume via NFS-Ganesha</td>
</tr>
<tr>
<td align="left">network.frame-timeout</td>
<td align="center">1800</td>
<td align="left">Time frame after which the (file) operation would be declared as dead, if the server does not respond for a particular (file) operation.</td>
</tr>
<tr>
<td align="left">network.ping-timeout</td>
<td align="center">42</td>
<td align="left">Time duration for which the client waits to check if the server is responsive.</td>
</tr>
<tr>
<td align="left">network.tcp-window-size</td>
<td align="center">null</td>
<td align="left">Specifies the window size for tcp socket.</td>
</tr>
<tr>
<td align="left">network.remote-dio</td>
<td align="center">disable</td>
<td align="left">If enabled, in open() and creat() calls, O_DIRECT flag will be filtered at the client protocol level so server will still continue to cache the file. This works similar to NFS’s behavior of O_DIRECT</td>
</tr>
<tr>
<td align="left">network.inode-lru-limit</td>
<td align="center">16384</td>
<td align="left">Specifies the maximum megabytes of memory to be used in the inode cache.</td>
</tr>
<tr>
<td align="left">network.compression</td>
<td align="center">off</td>
<td align="left">enable/disable network compression translator</td>
</tr>
<tr>
<td align="left">network.compression.window-size</td>
<td align="center">-15</td>
<td align="left">Size of the zlib history buffer.</td>
</tr>
<tr>
<td align="left">network.compression.mem-level</td>
<td align="center">8</td>
<td align="left">Memory allocated for internal compression state. 1 uses minimum memory but is slow and reduces compression ratio; memLevel=9 uses maximum memory for optimal speed. The default value is 8.</td>
</tr>
<tr>
<td align="left">network.compression.min-size</td>
<td align="center">0</td>
<td align="left">Data is compressed only when its size exceeds this.</td>
</tr>
<tr>
<td align="left">network.compression.compression-level</td>
<td align="center">-1</td>
<td align="left">Compression levels 0 : no compression, 1 : best speed, 9 : best compression, -1 : default compression</td>
</tr>
<tr>
<td align="left">features.lock-heal</td>
<td align="center">off</td>
<td align="left">When the connection to client is lost, server cleans up all the locks held by the client. After the connection is restored, the client reacquires (heals) the fcntl locks released by the server.</td>
</tr>
<tr>
<td align="left">features.grace-timeout</td>
<td align="center">10</td>
<td align="left">Specifies the duration for the lock state to be maintained on the client after a network disconnection. Range 10-1800 seconds.</td>
</tr>
<tr>
<td align="left">features.file-snapshot</td>
<td align="center">off</td>
<td align="left">enable/disable file-snapshot feature in the volume.</td>
</tr>
<tr>
<td align="left">features.uss</td>
<td align="center">off</td>
<td align="left">enable/disable User Serviceable Snapshots on the volume.</td>
</tr>
<tr>
<td align="left">features.snapshot-directory</td>
<td align="center">.snaps</td>
<td align="left">Entry point directory for entering snapshot world</td>
</tr>
<tr>
<td align="left">features.show-snapshot-directory</td>
<td align="center">off</td>
<td align="left">show entry point in readdir output of snapdir-entry-path which is set by samba</td>
</tr>
<tr>
<td align="left">features.quota-deem-statfs</td>
<td align="center">off</td>
<td align="left">If set to on, it takes quota limits intoconsideration while estimating fs size. (df command) (Default is off).</td>
</tr>
<tr>
<td align="left">features.read-only</td>
<td align="center">off</td>
<td align="left">When “on”, makes a volume read-only. It is turned “off” by default.</td>
</tr>
<tr>
<td align="left">features.worm</td>
<td align="center">off</td>
<td align="left">When “on”, makes a volume get write once read many feature. It is turned “off” by default.</td>
</tr>
<tr>
<td align="left">features.barrier-timeout</td>
<td align="center">120</td>
<td align="left">After ‘timeout’ seconds since the time ‘barrier’ option was set to “on”, acknowledgements to file operations are no longer blocked and previously blocked acknowledgements are sent to the application</td>
</tr>
<tr>
<td align="left">features.trash</td>
<td align="center">off</td>
<td align="left">Enable/disable trash translator</td>
</tr>
<tr>
<td align="left">features.trash-dir</td>
<td align="center">.trashcan</td>
<td align="left">Directory for trash files</td>
</tr>
<tr>
<td align="left">features.trash-eliminate-path</td>
<td align="center">(null)</td>
<td align="left">Eliminate paths to be excluded from trashing</td>
</tr>
<tr>
<td align="left">features.trash-max-filesize</td>
<td align="center">5MB</td>
<td align="left">Maximum size of file that can be moved to trash</td>
</tr>
<tr>
<td align="left">features.trash-internal-op</td>
<td align="center">off</td>
<td align="left">Enable/disable trash translator for internal operations</td>
</tr>
<tr>
<td align="left">features.ctr-enabled</td>
<td align="center">off</td>
<td align="left">Enable CTR xlator</td>
</tr>
<tr>
<td align="left">features.record-counters</td>
<td align="center">off</td>
<td align="left">Its a Change Time Recorder Xlator option to enable recording write and read heat counters. The default is disabled. If enabled, “cluster.write-freq-threshold” and “cluster.read-freq-threshold” defined the number of writes (or reads) to a given file are needed before triggering migration.</td>
</tr>
<tr>
<td align="left">features.ctr-sql-db-cachesize</td>
<td align="center">1000</td>
<td align="left">Defines the cache size of the sqlite database of changetimerecorder xlator.The input to this option is in pages.Each page is 4096 bytes. Default value is 1000 pages i.e ~ 4 MB. The max value is 262144 pages i.e 1 GB and the min value is 1000 pages i.e ~ 4 MB.</td>
</tr>
<tr>
<td align="left">features.ctr-sql-db-wal-autocheckpoint</td>
<td align="center">1000</td>
<td align="left">Defines the autocheckpoint of the sqlite database of changetimerecorder. The input to this option is in pages. Each page is 4096 bytes. Default value is 1000 pages i.e ~ 4 MB.The max value is 262144 pages i.e 1 GB and the min value is 1000 pages i.e ~4 MB.</td>
</tr>
<tr>
<td align="left">features.shard-block-size</td>
<td align="center">4MB</td>
<td align="left">The size unit used to break a file into multiple chunks</td>
</tr>
<tr>
<td align="left">features.cache-invalidation</td>
<td align="center">off</td>
<td align="left">When “on”, sends cache-invalidation notifications.</td>
</tr>
<tr>
<td align="left">features.cache-invalidation-timeout</td>
<td align="center">60</td>
<td align="left">After ‘timeout’ seconds since the time client accessed any file, cache-invalidation notifications are no longer sent to that client.</td>
</tr>
<tr>
<td align="left">client.event-threads</td>
<td align="center">2</td>
<td align="left">Specifies the number of event threads to execute in parallel. Larger values would help process responses faster, depending on available processing power. Range 1-32 threads.</td>
</tr>
<tr>
<td align="left">auth.allow</td>
<td align="center">null</td>
<td align="left">Allow a comma separated list of addresses and/or hostnames to connect to the server. Option auth.reject overrides this option. By default, all connections are allowed.</td>
</tr>
<tr>
<td align="left">auth.reject</td>
<td align="center">null</td>
<td align="left">Reject a comma separated list of addresses and/or hostnames to connect to the server. This option overrides the auth.allow option. By default, all connections are allowed.</td>
</tr>
<tr>
<td align="left">server.root-squash</td>
<td align="center">off</td>
<td align="left">Map requests from uid/gid 0 to the anonymous uid/gid. Note that this does not apply to any other uids or gids that might be equally sensitive, such as user bin or group staff.</td>
</tr>
<tr>
<td align="left">server.anonuid</td>
<td align="center">65534</td>
<td align="left">value of the uid used for the anonymous user/nfsnobody when root-squash is enabled.</td>
</tr>
<tr>
<td align="left">server.anongid</td>
<td align="center">65534</td>
<td align="left">value of the gid used for the anonymous user/nfsnobody when root-squash is enabled.</td>
</tr>
<tr>
<td align="left">server.statedump-path</td>
<td align="center">/var/run/gluster</td>
<td align="left">Specifies directory in which gluster should save its statedumps.</td>
</tr>
<tr>
<td align="left">server.outstanding-rpc-limit</td>
<td align="center">64</td>
<td align="left">Parameter to throttle the number of incoming RPC requests from a client. 0 means no limit (can potentially run out of memory)</td>
</tr>
<tr>
<td align="left">server.manage-gids</td>
<td align="center">off</td>
<td align="left">Resolve groups on the server-side.</td>
</tr>
<tr>
<td align="left">server.dynamic-auth</td>
<td align="center">on</td>
<td align="left">When ‘on’ perform dynamic authentication of volume options in order to allow/terminate client transport connection immediately in response to *.allow | *.reject volume set options.</td>
</tr>
<tr>
<td align="left">server.gid-timeout</td>
<td align="center">300</td>
<td align="left">Timeout in seconds for the cached groups to expire.</td>
</tr>
<tr>
<td align="left">server.event-threads</td>
<td align="center">2</td>
<td align="left">Specifies the number of event threads to execute in parallel. Larger values would help process responses faster, depending on available processing power. Range 1-32 threads.</td>
</tr>
<tr>
<td align="left">ssl.own-cert</td>
<td align="center">null</td>
<td align="left">SSL certificate. Ignored if SSL is not enabled.</td>
</tr>
<tr>
<td align="left">ssl.private-key</td>
<td align="center">null</td>
<td align="left">SSL private key. Ignored if SSL is not enabled.</td>
</tr>
<tr>
<td align="left">ssl.ca-list</td>
<td align="center">null</td>
<td align="left">SSL CA list. Ignored if SSL is not enabled.</td>
</tr>
<tr>
<td align="left">ssl.crl-path</td>
<td align="center">null</td>
<td align="left">Path to directory containing CRL. Ignored if SSL is not enabled.</td>
</tr>
<tr>
<td align="left">ssl.certificate-depth</td>
<td align="center">null</td>
<td align="left">Maximum certificate-chain depth. If zero, the peer’s certificate itself must be in the local certificate list. Otherwise, there may be up to N signing certificates between the peer’s and the local list. Ignored if SSL is not enabled.</td>
</tr>
<tr>
<td align="left">ssl.cipher-list</td>
<td align="center">null</td>
<td align="left">Allowed SSL ciphers. Ignored if SSL is not enabled.</td>
</tr>
<tr>
<td align="left">ssl.dh-param</td>
<td align="center">null</td>
<td align="left">DH parameters file. Ignored if SSL is not enabled.</td>
</tr>
<tr>
<td align="left">ssl.ec-curve</td>
<td align="center">null</td>
<td align="left">ECDH curve name. Ignored if SSL is not enabled.</td>
</tr>
<tr>
<td align="left">storage.linux-aio</td>
<td align="center">off</td>
<td align="left">Support for native Linux AIO</td>
</tr>
<tr>
<td align="left">storage.batch-fsync-mode</td>
<td align="center">reverse-fsync</td>
<td align="left">Possible values: syncfs: Perform one syncfs() on behalf oa batchof fsyncs. syncfs-single-fsync: Perform one syncfs() on behalf of a batch of fsyncs and one fsync() per batch. syncfs-reverse-fsync: Preform one syncfs() on behalf of a batch of fsyncs and fsync() each file in the batch in reverse order. reverse-fsync: Perform fsync() of each file in the batch in reverse order.</td>
</tr>
<tr>
<td align="left">storage.batch-fsync-delay-usec</td>
<td align="center">0</td>
<td align="left">Num of usecs to wait for aggregating fsync requests</td>
</tr>
<tr>
<td align="left">storage.owner-uid</td>
<td align="center">-1</td>
<td align="left">Support for setting uid of brick’s owner</td>
</tr>
<tr>
<td align="left">storage.owner-gid</td>
<td align="center">-1</td>
<td align="left">Support for setting gid of brick’s owner</td>
</tr>
<tr>
<td align="left">storage.node-uuid-pathinfo</td>
<td align="center">off</td>
<td align="left">return glusterd’s node-uuid in pathinfo xattr string instead of hostname</td>
</tr>
<tr>
<td align="left">storage.health-check-interval</td>
<td align="center">30</td>
<td align="left">Interval in seconds for a filesystem health check, set to 0 to disable</td>
</tr>
<tr>
<td align="left">storage.build-pgfid</td>
<td align="center">off</td>
<td align="left">Enable placeholders for gfid to path conversion</td>
</tr>
<tr>
<td align="left">storage.bd-aio</td>
<td align="center">off</td>
<td align="left">Support for native Linux AIO</td>
</tr>
</tbody></table>
<h2 id="GlusterFS的优化样例"><a href="#GlusterFS的优化样例" class="headerlink" title="GlusterFS的优化样例"></a>GlusterFS的优化样例</h2><table>
<thead>
<tr>
<th align="left">选项</th>
<th align="center">配置</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left">cluster.server-quorum-type</td>
<td align="center">server</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">cluster.quorum-type</td>
<td align="center">auto</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">network.remote-dio</td>
<td align="center">enable</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">cluster.eager-lock</td>
<td align="center">enable</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">performance.stat-prefetch</td>
<td align="center">off</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">performance.io-cache</td>
<td align="center">off</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">performance.read-ahead</td>
<td align="center">off</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">performance.quick-read</td>
<td align="center">off</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">performance.readdir-ahead</td>
<td align="center"></td>
<td align="left"></td>
</tr>
</tbody></table>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/3/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">perrynzhou</p>
  <div class="site-description" itemprop="description">涉猎的主要编程语言为 C、Go，分布式存储和对象存储.https://github.com/perrynzhou。</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">36</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>



<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">perrynzhou</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
